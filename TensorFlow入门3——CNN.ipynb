{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 face='黑体'>使用CNN进行MNIST数据集分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting F:\\data\\mnist_data\\MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting F:\\data\\mnist_data\\MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting F:\\data\\mnist_data\\MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting F:\\data\\mnist_data\\MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('F:\\data\\mnist_data\\MNIST_data',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter0 Testing Accuracy:0.9796\n",
      "Iter1 Testing Accuracy:0.9834\n",
      "Iter2 Testing Accuracy:0.9895\n",
      "Iter3 Testing Accuracy:0.9885\n",
      "Iter4 Testing Accuracy:0.9901\n",
      "Iter5 Testing Accuracy:0.9917\n",
      "Iter6 Testing Accuracy:0.9909\n",
      "Iter7 Testing Accuracy:0.99\n",
      "Iter8 Testing Accuracy:0.9907\n",
      "Iter9 Testing Accuracy:0.9923\n",
      "Iter10 Testing Accuracy:0.992\n",
      "Iter11 Testing Accuracy:0.9918\n",
      "Iter12 Testing Accuracy:0.9914\n",
      "Iter13 Testing Accuracy:0.9922\n",
      "Iter14 Testing Accuracy:0.9915\n",
      "Iter15 Testing Accuracy:0.9905\n",
      "Iter16 Testing Accuracy:0.9914\n",
      "Iter17 Testing Accuracy:0.9929\n",
      "Iter18 Testing Accuracy:0.9912\n",
      "Iter19 Testing Accuracy:0.993\n",
      "Iter20 Testing Accuracy:0.9921\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "def weight_variable(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape,stddev=0.1))\n",
    "\n",
    "def bias_variable(shape):\n",
    "    return tf.Variable(tf.constant(0.1,shape=shape))\n",
    "\n",
    "def conv2d(x,W):\n",
    "    #x为输入数据，形状为[N,H,W,C]；W为滤波器，形状为[H,W,C,N]\n",
    "    #strides[0]和stridess[3]只能等于1，strides[1,2]分别表示x，y方向上的步幅\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "x_image = tf.reshape(x,[-1,28,28,1])\n",
    "\n",
    "W_conv1 = weight_variable([4,4,1,16])  #4 * 4 的采样窗口，16个滤波器一共生成16张特征图\n",
    "b_conv1 = bias_variable([16])\n",
    "\n",
    "#28*28*1 的图片卷积之后变为 28*28*16\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1) + b_conv1)\n",
    "#池化后变成 14*14*16\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "#第二次卷积之后变为 14*14*16\n",
    "W_conv2 = weight_variable([4,4,16,16])\n",
    "b_conv2 = bias_variable([16])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2) + b_conv2)\n",
    "#第二次池化后变为 7*7*16\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "#第一个全连接层 \n",
    "W_fc1 = weight_variable([7*7*16,500])\n",
    "b_fc1 = bias_variable([500])\n",
    "#7*7*16的图像输出变为1维向量进行输入\n",
    "h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*16])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1) + b_fc1)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)\n",
    "\n",
    "#第二个全连接层\n",
    "W_fc2  = weight_variable([500,10])\n",
    "b_fc2 =  bias_variable([10])\n",
    "a2 = tf.matmul(h_fc1_drop,W_fc2) + b_fc2\n",
    "prediction = tf.nn.softmax(a2)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=a2))\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "\n",
    "correct = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_x,batch_y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_x,y:batch_y,keep_prob:0.7})\n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels,\n",
    "                                          keep_prob:1.0})\n",
    "        print('Iter'+str(epoch)+' Testing Accuracy:'+str(acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 face='黑体'>构建网络结构,并可视化数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step0 Testing Accuracy:0.1314\n",
      "Step10 Testing Accuracy:0.6259\n",
      "Step20 Testing Accuracy:0.7745\n",
      "Step30 Testing Accuracy:0.8511\n",
      "Step40 Testing Accuracy:0.8828\n",
      "Step50 Testing Accuracy:0.9059\n",
      "Step60 Testing Accuracy:0.9172\n",
      "Step70 Testing Accuracy:0.9241\n",
      "Step80 Testing Accuracy:0.9337\n",
      "Step90 Testing Accuracy:0.9344\n",
      "Step100 Testing Accuracy:0.9421\n",
      "Step110 Testing Accuracy:0.948\n",
      "Step120 Testing Accuracy:0.9544\n",
      "Step130 Testing Accuracy:0.9521\n",
      "Step140 Testing Accuracy:0.953\n",
      "Step150 Testing Accuracy:0.9535\n",
      "Step160 Testing Accuracy:0.9564\n",
      "Step170 Testing Accuracy:0.9593\n",
      "Step180 Testing Accuracy:0.9639\n",
      "Step190 Testing Accuracy:0.9644\n",
      "Step200 Testing Accuracy:0.9625\n",
      "Step210 Testing Accuracy:0.9616\n",
      "Step220 Testing Accuracy:0.969\n",
      "Step230 Testing Accuracy:0.966\n",
      "Step240 Testing Accuracy:0.9708\n",
      "Step250 Testing Accuracy:0.9746\n",
      "Step260 Testing Accuracy:0.9732\n",
      "Step270 Testing Accuracy:0.9745\n",
      "Step280 Testing Accuracy:0.9751\n",
      "Step290 Testing Accuracy:0.9763\n",
      "Step300 Testing Accuracy:0.9748\n",
      "Step310 Testing Accuracy:0.9732\n",
      "Step320 Testing Accuracy:0.9772\n",
      "Step330 Testing Accuracy:0.9747\n",
      "Step340 Testing Accuracy:0.9743\n",
      "Step350 Testing Accuracy:0.9772\n",
      "Step360 Testing Accuracy:0.9775\n",
      "Step370 Testing Accuracy:0.9777\n",
      "Step380 Testing Accuracy:0.9806\n",
      "Step390 Testing Accuracy:0.9799\n",
      "Step400 Testing Accuracy:0.9815\n",
      "Step410 Testing Accuracy:0.9797\n",
      "Step420 Testing Accuracy:0.9791\n",
      "Step430 Testing Accuracy:0.9808\n",
      "Step440 Testing Accuracy:0.9818\n",
      "Step450 Testing Accuracy:0.9787\n",
      "Step460 Testing Accuracy:0.9795\n",
      "Step470 Testing Accuracy:0.9782\n",
      "Step480 Testing Accuracy:0.9788\n",
      "Step490 Testing Accuracy:0.9789\n",
      "Step500 Testing Accuracy:0.9794\n",
      "Step510 Testing Accuracy:0.9822\n",
      "Step520 Testing Accuracy:0.9833\n",
      "Step530 Testing Accuracy:0.9833\n",
      "Step540 Testing Accuracy:0.9832\n",
      "Step550 Testing Accuracy:0.9835\n",
      "Step560 Testing Accuracy:0.9832\n",
      "Step570 Testing Accuracy:0.9809\n",
      "Step580 Testing Accuracy:0.9838\n",
      "Step590 Testing Accuracy:0.9834\n",
      "Step600 Testing Accuracy:0.9836\n",
      "Step610 Testing Accuracy:0.9807\n",
      "Step620 Testing Accuracy:0.9825\n",
      "Step630 Testing Accuracy:0.9836\n",
      "Step640 Testing Accuracy:0.9824\n",
      "Step650 Testing Accuracy:0.9823\n",
      "Step660 Testing Accuracy:0.9823\n",
      "Step670 Testing Accuracy:0.9852\n",
      "Step680 Testing Accuracy:0.9849\n",
      "Step690 Testing Accuracy:0.985\n",
      "Step700 Testing Accuracy:0.9802\n",
      "Step710 Testing Accuracy:0.9848\n",
      "Step720 Testing Accuracy:0.9839\n",
      "Step730 Testing Accuracy:0.9843\n",
      "Step740 Testing Accuracy:0.9863\n",
      "Step750 Testing Accuracy:0.9859\n",
      "Step760 Testing Accuracy:0.985\n",
      "Step770 Testing Accuracy:0.9841\n",
      "Step780 Testing Accuracy:0.9841\n",
      "Step790 Testing Accuracy:0.9836\n",
      "Step800 Testing Accuracy:0.988\n",
      "Step810 Testing Accuracy:0.9861\n",
      "Step820 Testing Accuracy:0.986\n",
      "Step830 Testing Accuracy:0.985\n",
      "Step840 Testing Accuracy:0.9862\n",
      "Step850 Testing Accuracy:0.9856\n",
      "Step860 Testing Accuracy:0.987\n",
      "Step870 Testing Accuracy:0.986\n",
      "Step880 Testing Accuracy:0.988\n",
      "Step890 Testing Accuracy:0.988\n",
      "Step900 Testing Accuracy:0.986\n",
      "Step910 Testing Accuracy:0.9872\n",
      "Step920 Testing Accuracy:0.9846\n",
      "Step930 Testing Accuracy:0.9862\n",
      "Step940 Testing Accuracy:0.9862\n",
      "Step950 Testing Accuracy:0.9863\n",
      "Step960 Testing Accuracy:0.9857\n",
      "Step970 Testing Accuracy:0.9872\n",
      "Step980 Testing Accuracy:0.9872\n",
      "Step990 Testing Accuracy:0.9859\n",
      "Step1000 Testing Accuracy:0.9876\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "max_step = 1001\n",
    "k = 0.8\n",
    "\n",
    "def weight_variable(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape,stddev=0.1),name='W')\n",
    "\n",
    "def bias_variable(shape):\n",
    "    return tf.Variable(tf.constant(0.1,shape=shape),name='b')\n",
    "\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME',name='conv2d')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME',name='Max_pool')\n",
    "\n",
    "#记录变量的函数\n",
    "def variable_summary(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean',mean)\n",
    "        stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev',stddev)\n",
    "        tf.summary.scalar('max',tf.reduce_max(var))\n",
    "        tf.summary.scalar('min',tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram',var)\n",
    "        \n",
    "#结构化卷积层的函数\n",
    "def conv_layer(input_tensor,weight_shape,layer_name):\n",
    "    with tf.name_scope(layer_name):\n",
    "        with tf.name_scope('weights'):\n",
    "            weights = weight_variable(weight_shape)\n",
    "            variable_summary(weights)\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = bias_variable([weight_shape[-1]])\n",
    "            variable_summary(biases)\n",
    "        with tf.name_scope('conv_comput'):\n",
    "            preactivate = conv2d(input_tensor,weights) + biases\n",
    "        with tf.name_scope('activate'):\n",
    "            activations = tf.nn.relu(preactivate)\n",
    "        return activations\n",
    "    \n",
    "#结构化全连接层的函数\n",
    "def linear_layer(input_tensor,input_dim,output_dim,layer_name):\n",
    "    with tf.name_scope(layer_name):\n",
    "        with tf.name_scope('weights'):\n",
    "            weights = weight_variable([input_dim,output_dim])\n",
    "            variable_summary(weights)\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = bias_variable([output_dim])\n",
    "            variable_summary(biases)\n",
    "        with tf.name_scope('linear_comput'):\n",
    "            preactivate = tf.matmul(input_tensor,weights) + biases\n",
    "        return preactivate\n",
    "    \n",
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32,[None,784],name='x_input')\n",
    "    with tf.name_scope('input_reshape'):\n",
    "        x_image = tf.reshape(x,[-1,28,28,1],name='x_image')\n",
    "        #tf.summary.image('input',x_image,10)\n",
    "    y = tf.placeholder(tf.float32,[None,10],name='y_input')\n",
    "    keep_prob = tf.placeholder(tf.float32,name='keep_prob')\n",
    "    \n",
    "#第一次卷积 28*28*1 -> 28*28*16\n",
    "conv_layer1 = conv_layer(x_image,[4,4,1,16],'conv_layer1')\n",
    "#第一次池化 28*28*16 -> 14*14*16\n",
    "with tf.name_scope('Max_pool1'):\n",
    "    h_pool1 = max_pool_2x2(conv_layer1)\n",
    "    \n",
    "#第二次卷积 14*14*16 -> 14*14*32\n",
    "conv_layer2 = conv_layer(h_pool1,[3,3,16,32],'conv_layer2')\n",
    "#第二次池化 14*14*32 -> 7*7*32\n",
    "with tf.name_scope('Max_pool2'):\n",
    "    h_pool2 = max_pool_2x2(conv_layer2)\n",
    "\n",
    "with tf.name_scope('flatten'):\n",
    "    flatten = tf.reshape(h_pool2,[-1,7*7*32])\n",
    "\n",
    "#第一个全连接层\n",
    "fc1 = linear_layer(flatten,7*7*32,500,'FC1')\n",
    "\n",
    "with tf.name_scope('activate'):\n",
    "    activations = tf.nn.relu(fc1)\n",
    "        \n",
    "with tf.name_scope('dropout'):\n",
    "    fc1_drop = tf.nn.dropout(activations,keep_prob)\n",
    "    \n",
    "#第二个全连接层\n",
    "fc2 = linear_layer(fc1_drop,500,10,'FC2')\n",
    "\n",
    "with  tf.name_scope('activate'):\n",
    "    prediction = tf.nn.softmax(fc2)\n",
    "    \n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=fc2))\n",
    "    tf.summary.scalar('loss',loss)\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "    \n",
    "with tf.name_scope('Accuracy'):\n",
    "    correct = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))\n",
    "    tf.summary.scalar('accuracy',accuracy)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter(r'F:\\data\\mnist_data\\logs',sess.graph)\n",
    "    \n",
    "    for i in range(max_step):\n",
    "        batch_x,batch_y = mnist.train.next_batch(batch_size)\n",
    "        sess.run(train_step,feed_dict={x:batch_x,y:batch_y,keep_prob:k})\n",
    "        \n",
    "        if i%10 == 0:\n",
    "            summary,acc = sess.run([merged,accuracy],feed_dict={x:mnist.test.images,y:mnist.test.labels,\n",
    "                                          keep_prob:1.})\n",
    "            writer.add_summary(summary,i)\n",
    "            print('Step'+str(i)+' Testing Accuracy:'+str(acc))\n",
    "            \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
